{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[ 0.46613554,  0.92048757],\n",
    "       [-0.92129195,  0.06723639],\n",
    "       [-0.15836636,  0.00430243],\n",
    "       [-0.24055905, -0.87032292],\n",
    "       [ 0.06245105, -0.53698416],\n",
    "       [-0.2265037 , -0.43835751],\n",
    "       [-0.00480479, -0.17372081],\n",
    "       [-0.1525277 , -0.34399658],\n",
    "       [-0.27360329,  0.35339202],\n",
    "       [-0.77464508, -0.48715511],\n",
    "       [-0.58724291,  0.74419972],\n",
    "       [-0.97596949, -0.72172963],\n",
    "       [ 0.42376225, -0.72655597],\n",
    "       [ 0.96383922, -0.23371331],\n",
    "       [ 0.16264643, -0.46949742],\n",
    "       [-0.74294705, -0.42576417],\n",
    "       [ 0.05089437, -0.20522071],\n",
    "       [-0.19442744,  0.09617478],\n",
    "       [-0.97102743,  0.79663992],\n",
    "       [ 0.0596995 , -0.70129219],\n",
    "       [-0.83934851, -0.95616033],\n",
    "       [-0.38249705,  0.4973605 ],\n",
    "       [ 0.3474666 ,  0.70664397],\n",
    "       [ 0.35871444,  0.88679345],\n",
    "       [-0.05914582,  0.23124686],\n",
    "       [-0.52156643,  0.32986941],\n",
    "       [-0.53579646,  0.67530208],\n",
    "       [ 0.13683914, -0.96158184],\n",
    "       [ 0.65904541, -0.12015303],\n",
    "       [-0.69078363,  0.5615536 ],\n",
    "       [ 0.47738323, -0.70919275],\n",
    "       [ 0.93069669,  0.44019132],\n",
    "       [ 0.19750088, -0.68869404],\n",
    "       [-0.75048675, -0.18170522],\n",
    "       [-0.45288395, -0.25894991],\n",
    "       [-0.74644547,  0.87781953],\n",
    "       [ 0.14620452,  0.56864508],\n",
    "       [ 0.25719272, -0.58405476],\n",
    "       [ 0.87149524,  0.01384224],\n",
    "       [-0.71473576,  0.31568314],\n",
    "       [-0.252637  , -0.67418371],\n",
    "       [ 0.24718308,  0.95191416],\n",
    "       [-0.38149953, -0.64066291],\n",
    "       [-0.23112698,  0.04678807],\n",
    "       [ 0.72631766,  0.7390158 ],\n",
    "       [-0.91748062, -0.15131021],\n",
    "       [ 0.74957917,  0.66966866],\n",
    "       [ 0.76771849,  0.06662777],\n",
    "       [-0.04233756, -0.91320835],\n",
    "       [ 0.63840333,  0.06277738],\n",
    "       [-0.78887281, -0.90311183],\n",
    "       [-0.73099834, -0.69587363],\n",
    "       [-0.50947652, -0.99144951],\n",
    "       [ 0.14294609,  0.5474932 ],\n",
    "       [ 0.4367906 ,  0.31953258],\n",
    "       [-0.13970851,  0.81817884],\n",
    "       [ 0.6440873 ,  0.79118775],\n",
    "       [ 0.41714043, -0.66672029],\n",
    "       [ 0.59283022, -0.71836746],\n",
    "       [ 0.55379696,  0.98846202],\n",
    "       [-0.91819517,  0.34203895],\n",
    "       [ 0.02020188,  0.83696694],\n",
    "       [ 0.6182918 ,  0.04254014],\n",
    "       [-0.09354765, -0.30050483],\n",
    "       [-0.08489545,  0.06431463],\n",
    "       [-0.11886358, -0.68738895],\n",
    "       [ 0.44428375,  0.18273761],\n",
    "       [ 0.26486362, -0.98398013],\n",
    "       [ 0.13222452,  0.91495035],\n",
    "       [-0.11101656,  0.00541343],\n",
    "       [-0.07696178, -0.92720555],\n",
    "       [ 0.22602214,  0.56040092],\n",
    "       [ 0.74227542,  0.32930104],\n",
    "       [ 0.43524657,  0.35332933],\n",
    "       [-0.89277607, -0.59996171],\n",
    "       [-0.94836212,  0.78777302],\n",
    "       [ 0.1783319 , -0.2142071 ],\n",
    "       [-0.07832238, -0.25046584],\n",
    "       [ 0.17611799, -0.96927832],\n",
    "       [-0.95938454, -0.26504646],\n",
    "       [ 0.58666766, -0.94620881],\n",
    "       [-0.77336565,  0.46735057],\n",
    "       [-0.94414054,  0.39044333],\n",
    "       [ 0.61524645,  0.15907662],\n",
    "       [-0.09855302,  0.9816656 ],\n",
    "       [ 0.53937097,  0.34487634]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [\"red\" if x + y > 0.3 else \"green\"  for [x,y] in X]\n",
    "y1 = [+1 if x + y > 0.3 else -1  for [x,y] in X]\n",
    "#y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=y)"
   ]
  },
  {
   "source": [
    "# SVM by *hand*\n",
    "\n",
    "Let us use scipy.optimize.minimize to learn the SVM solution to the classification problem given above\n",
    "\n",
    "Scipy has a quite powerful optimizer that we can use to quite easily implement the SVM primal optimization problem.\n",
    "\n",
    "We start by noticing that the optimizer does not support non-homogeneous coordinates. We just add a column of 1s to the matrix $X$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consiglio: scrivere la matrice in cordinate omogenee (aggiunta una colonna di 1 alla colonna X, slide 5 LinearModels)\n",
    "X = np.append(X, np.ones([len(X), 1]), 1)"
   ]
  },
  {
   "source": [
    "We then define the objective function we want to minimize..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# occhio perchè x conterrà il temine noto, è da rimuovere prima di calcolare la funzione!\n",
    "def objfun(x, *args):\n",
    "    return 0.5 * np.square(np.linalg.norm(X[:,:-1]))\n",
    "    "
   ]
  },
  {
   "source": [
    "The most challenging part is to define the constraints for the problem. The scipy optimizer needs them in the form:\n",
    "\n",
    "$\\textit{lb} \\leq \\mathbf{A} \\cdot \\mathbf{x} \\leq \\textit{ub}$\n",
    "\n",
    "where $x$ is the current set of linear parameters we are learning and are provided by the optimizer. We then have to devise a matrix $A$ and upper bounds *lb* and *ub* to model the ones we need for the SVM problem.\n",
    "\n",
    "Note: *lb* and *ub* can be set to $+\\infty$ (using `+np.inf`) or $-\\infty$ (using `-np.inf`) if necessary.\n",
    "\n",
    "Once we have defined $A$, *lb* and *ub*, the linear constraint can be created using:\n",
    "\n",
    "`lc = scipy.optimize.LinearConstraint(A, lb, ub)`\n",
    "\n",
    "Finally, to invoke the optimizer we also need a starting point for the numerical search (0,0,0) would do just fine in this case"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = (y1 * X.T).T # moltiplicazione del vettore Y1 con ogni riga della matrice X\n",
    "\n",
    "# da notare che A = W nelle nostre formule e inoltre TODO: guarda le formule sol tuo foglio di brutta\n"
   ]
  },
  {
   "source": [
    "Nota bene: \n",
    "\n",
    "1. $\\mathbf{A}$ è l'oggetto che per noi negli appunti è $\\mathbf{w}$\n",
    "\n",
    "2. Dato il punto 1, il vincolo di maggioranza rispetto al limite inferirore si trasforma nel seguente modo:\n",
    "\n",
    "$y_i(w * x_i -t) \\ge 1$\n",
    "\n",
    "$y_i * w * x_i - y_i * t$ raccolgo la $w$\n",
    "\n",
    "$w * [y_i * x_i] - y_i * t$ poiché $y_i * t$ è un termine costante posso non considerarlo nella prossima equazione\n",
    "\n",
    "$w * [y_i * x_i]$\n",
    "\n",
    "$w = y_i * x_i$ TODO: formule da controllare! L'idea è giusta, ma la formulazione matematica è sbagliata!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ub = +np.inf\n",
    "lb = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = scipy.optimize.LinearConstraint(A, lb, ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = np.zeros(X.shape[1]) # punto iniziale al quale iniziare la ricerca (w1, w2, t)\n",
    "w = scipy.optimize.minimize(objfun, w0, constraints=[lc])\n",
    "#w\n",
    "w.x # format w.x -> w = [w1, w2, w3] -> (x, y, t)"
   ]
  },
  {
   "source": [
    "Let us now plot the results. A function can be plotted using matplotlib by creating the $x$ values `xs`, computing the corresponding $y$ values `ys` and using:\n",
    "\n",
    "`plt.plot(xs,ys)`\n",
    "\n",
    "**Note**: An easy way to create the $x$ values is:\n",
    "\n",
    "`xs = np.linspace(a,b)`\n",
    "\n",
    "which would create a sequence of equally spaced real numbers between `a` and `b`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mathplotlib non ha una funzione che plotta direttamente la retta tramite una funzione callable, per cui dobbiamo farlo noi a mano\n",
    "m = -w.x[0]/w.x[1] # coefficiente angolare\n",
    "t = -w.x[2]/w.x[1] # punto intersezione\n",
    "\n",
    "xs = np.linspace(-1,1)\n",
    "ys = xs*m + t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xs,ys)\n",
    "plt.scatter(X[:,0], X[:,1], c=y)"
   ]
  },
  {
   "source": [
    "## Some additional question for preparing to the exam\n",
    "\n",
    "- import the support vector machine classifier from scikit-learn (the SVC class) and train a classifier for the examples above using a linear kernel;\n",
    "- read the documentation to find out how to obtain the support vectors and the associated (dual) weights; use this information to analyze the learnt model: \n",
    "    - how many support vectors have been learnt? \n",
    "    - are them in the position you would have expected [[1](#note1)]? \n",
    "    - is there any margin error?\n",
    "    - is there any classification error (check it using the classifier predictions)?\n",
    "- learn a new SVC model using custom C values:\n",
    "    - how the answers to the questions above change when you use a very high C value (e.g., 1000)?\n",
    "    - how the answers to the questions above change when you use a very low C value (e.g., 0.3)?\n",
    "- learn a new SVC model using a rbf kernel:\n",
    "    - is the new kernel able to capture the linear model?\n",
    "    - are you surprised by the above answer? Regarless to whether you are surprised or not: why?\n",
    "    \n",
    "<a name=\"note1\">[1]</a> If you make two plots one after the other (in the same cell), the plots will be merged into a single one. You may want to use this feature to plot the support vectors on top of the scatter plot for the dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('aaut': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a07757eebbb88d9274b59226e18b77a2dd1d919e3b61c48eb9c7966fb3bb6670"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}